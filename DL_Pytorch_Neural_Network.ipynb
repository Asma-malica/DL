{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asma-malica/DL/blob/main/DL_Pytorch_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSIFICATION**"
      ],
      "metadata": {
        "id": "j1zaqLTKYEwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if_8bzM9mvtK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdO2zrnzoFZ3"
      },
      "outputs": [],
      "source": [
        "# before importing the data we wanna transform the data (transform is nothing but normal normalization )\n",
        "\n",
        "# Normalization --> scales to a range between 0 & 1 (Ex : Min Max Scaler)\n",
        "# Standardization --> Centers data around the mean and scales to a standard deviation of 1 (Ex : Standard Scaler)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIMLSIqTqQDs",
        "outputId": "06b2b02a-54a1-433a-9b89-d7fb0eebd90f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 71877942.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 18792381.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24249098.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2133556.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Taking the dataset\n",
        "train_dataset=datasets.MNIST('data',\n",
        "                             train=True,\n",
        "                             download=True,transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCVJQTmyqZKx"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFhTF4QTzeb4"
      },
      "outputs": [],
      "source": [
        "# defining the model\n",
        "\n",
        "class Neural(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Neural,self).__init__()\n",
        "    self.fc1=nn.Linear(28*28,128)  #128 --> o/p\n",
        "    self.fc2=nn.Linear(128,10)  #here 128 is passed as i/p and 10 is a class\n",
        "  def forward(self,x):\n",
        "    x=x.view(-1,28*28)\n",
        "    x=torch.relu(self.fc1(x)) #Applied the relu\n",
        "    x=self.fc2(x)\n",
        "    return x\n",
        "net=Neural()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCv-8ITWzmuO"
      },
      "outputs": [],
      "source": [
        "#defining the class and optimizer --> optimization algorithm (can set learning_rate and momentum)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMibxuNB1mxm",
        "outputId": "6591a60b-fbda-4eca-fbcf-849e77d498b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.357905\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.521270\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.374348\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.307103\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.229255\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.211444\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.241872\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.264480\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.471519\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.268595\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.257516\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.244730\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.215424\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.330815\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.143220\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.277181\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.182573\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.081138\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.530174\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.072238\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.198452\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.252678\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.175145\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.228735\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.145433\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.179532\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.152278\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.302067\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.162994\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.127733\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.241902\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.177367\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.127552\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.243317\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.079343\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.175191\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.103442\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.100951\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.170519\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.091024\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.135204\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.343219\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.065634\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.090750\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.070825\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.148473\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.040370\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.195036\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.200768\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.141055\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.168037\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.103672\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.053441\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.258282\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.200068\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.260717\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.128878\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.091102\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.140603\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.108454\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.103693\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.118854\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.142742\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.097252\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.168197\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.043296\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.077129\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.207634\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.080221\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.041771\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.227496\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.113548\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.088689\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.027923\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.069018\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.109209\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.029491\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.025694\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.141533\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.089415\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.039643\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.085330\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.055974\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.086304\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.093655\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.198258\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.030416\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.108489\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.080500\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.042439\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.058391\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.049353\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.054764\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.143451\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.059135\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.038342\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.041122\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.062979\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.172207\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.043305\n"
          ]
        }
      ],
      "source": [
        "#Train the model\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data,target) in enumerate (train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output=net(data)\n",
        "    loss =criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 100==0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxUcjFPd2Gj-"
      },
      "outputs": [],
      "source": [
        "# Load the test data and test the model\n",
        "\n",
        "test_dataset=datasets.MNIST('data',train=False,download=True,transform=transform)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=1000,shuffle=True)\n",
        "correct=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "  output=net(data)\n",
        "  _,predicted=torch.max(output.data,1)\n",
        "  total+=target.size(0)\n",
        "  correct+=(predicted==target).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtVc5N0g2w0W",
        "outputId": "b9a7edcf-87b5-463d-a4e4-a28eabda14a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 96 %\n"
          ]
        }
      ],
      "source": [
        "#Accuracy\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfLtdP3Q568j"
      },
      "source": [
        "**ADDING ANOTHER HIDDEN LAYER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh2895BB3RhW",
        "outputId": "89c31f8e-fb29-47a0-cf43-521efcef4e5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.344378\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.124850\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.542350\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.505829\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.318512\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.419964\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.244681\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.369982\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.248724\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.159881\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.269563\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.289578\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.335619\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.416112\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.217797\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.155490\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.242012\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.169129\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.237874\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.070532\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.382914\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.303549\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.191517\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.078271\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.156201\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.161180\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.139419\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.129132\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.184181\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.200834\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.119442\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.195693\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.054438\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.181445\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.140309\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.205670\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.059812\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.081615\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.139272\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.227505\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.149492\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.122838\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.067221\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.137981\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.048258\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.071806\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.154258\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.251719\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.037424\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.128369\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.046740\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.039356\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.067920\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.071198\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.114201\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.096351\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.053869\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.103690\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.279477\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.109766\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.038306\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.058687\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.216177\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.028415\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.086685\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.034133\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.109758\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.142281\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.076148\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.073902\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.124402\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.063708\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.081578\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.204316\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.155917\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.041790\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.086022\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.084064\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.101577\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.025208\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.028134\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.043798\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.113408\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.128382\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.097510\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.093753\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.049364\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.038449\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.060020\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.054533\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.065257\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.042328\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.090487\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.015786\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.046422\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.147813\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.021179\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.013489\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.020427\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.047967\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)  # Added another hidden layer\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))  # Applied relu to the output of the second hidden layer\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Neural()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = net(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZS1KDsf48G2",
        "outputId": "6ed35b0a-6d89-475f-c890-a892f58e2eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.57%\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy of the network on the 10000 test images: {:.2f}%'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KjvFYbJ636C",
        "outputId": "ea6050ff-006c-4d32-a450-e0b8b6ea9f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.334313\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.551809\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.440091\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.601866\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.481555\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.531551\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.285887\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.332500\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.262104\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.226021\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.176100\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.202752\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.273895\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.220748\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.340006\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.142227\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.092363\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.227571\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.321456\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.145033\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.219657\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.211677\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.509673\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.227146\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.240170\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.217418\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.160207\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.275317\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.320163\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.295362\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.166226\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.130606\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.143743\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.135001\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.077869\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.085007\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.067711\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.064067\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.238059\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.364364\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.234404\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.087848\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.268544\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.397425\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.437696\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.128323\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.118230\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.207068\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.232772\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.342509\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.183744\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.128542\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.189771\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.060986\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.211818\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.130799\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.245195\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.122949\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.200784\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.303507\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.066358\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.093922\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.162010\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.077542\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.191028\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.149740\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.183739\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.127667\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.121151\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.080630\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.092602\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.229374\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.122793\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.148650\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.215685\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.237092\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.137929\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.156295\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.166638\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.145920\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.069854\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.071509\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.164834\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.131393\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.043319\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.259387\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.122142\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.113851\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.070118\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.194246\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.165530\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.098124\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.095209\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.138924\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.037928\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.115102\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.127455\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.299972\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.183179\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.105738\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.063683\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.064997\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.031076\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.084350\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.069407\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.178754\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.044529\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.080483\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.030924\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.135675\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.066042\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.159239\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.016585\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.024470\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.074726\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.046448\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.248931\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.013746\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.045225\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.088522\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.041364\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.019960\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.158387\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.189364\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.060789\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.207506\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.106357\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.103254\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.072968\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.225008\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.009173\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.077837\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.090878\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.184575\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.017887\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.107434\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.074781\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.043458\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.109281\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.204337\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.093208\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.074037\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.097768\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.163207\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.018603\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.074977\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.066740\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.087144\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.062119\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.060787\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Neural()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = net(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04s-BiM-66cF",
        "outputId": "0cdb1c64-5222-4b2d-ce07-9a938a80bfc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 96.16%\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy of the network on the 10000 test images: {:.2f}%'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKVbt7kD-FtR"
      },
      "source": [
        "**NEW DATASET FROM PYTORCH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0MKV48T-066",
        "outputId": "1ace26c1-aa66-4abe-9ed0-b9ff4f52f1d6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 40969633.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.306089\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.115882\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.013667\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.925207\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.760683\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.549853\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.717990\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.819183\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.675266\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.760288\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.702732\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.806538\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.538790\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.419717\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.744104\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.588960\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.583310\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.502585\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.616889\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.360566\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.473081\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.420379\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.597849\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.355748\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.339211\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.372611\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.434224\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.559999\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.414300\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.251107\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.502053\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.318511\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.280892\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.410342\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.219628\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.289740\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.203390\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.393707\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.354373\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.384950\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.266212\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.316347\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.284186\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.323877\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.406947\n",
            "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.396634\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.226692\n",
            "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.208002\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.252546\n",
            "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.277949\n",
            "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.319134\n",
            "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 1.219293\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.317095\n",
            "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 1.309571\n",
            "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.293725\n",
            "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 1.273840\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.247122\n",
            "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 1.347970\n",
            "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.271100\n",
            "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 1.276327\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.361038\n",
            "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 1.314797\n",
            "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.147761\n",
            "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 1.307607\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.236828\n",
            "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 1.125452\n",
            "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.141753\n",
            "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 1.390535\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.130050\n",
            "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 1.234787\n",
            "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.235322\n",
            "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 1.206900\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.121478\n",
            "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 1.062768\n",
            "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.268438\n",
            "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 1.247491\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.284390\n",
            "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 1.112610\n",
            "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.082166\n",
            "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 1.140504\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural, self).__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32 * 32 * 3)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "net = Neural()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_dataset = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = net(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: {:.2f}%'.format(\n",
        "    100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr_Sal9hCQ09"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgA2eYKXgtU+PNaKiu/tkF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}